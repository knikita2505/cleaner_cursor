# План оптимизации сканирования фотографий (дубликаты + похожие)

## Цель
Сильно ускорить анализ дубликатов и похожих фото, не теряя точности.  
Тяжёлые категории должны работать быстрее, использовать многоступенчатый pipeline и не блокировать UI.

---

## 1. Ввести двухэтапный pipeline анализа

### Быстрый этап (очень быстрый)
- Для всех PHAsset загружать уменьшенные миниатюры 64×64 или 128×128  
- Генерировать pHash  
- Сохранять `assetID + pHash` в лёгкий кэш

### Тяжёлый этап (фоновый)
- Для групп с одинаковым или близким pHash запускать Vision `VNGenerateImageFeaturePrintRequest`  
- Выполнять Vision **батчами**, а не по одному фото  
- Уточнять группы дубликатов и похожих фото

---

## 2. Исключить анализ полноразмерных изображений
- Не загружать full-size data  
- Использовать уменьшенные превью (`deliveryMode = .fastFormat`)  
- Ускорение в 20–40 раз

---

## 3. Добавить постоянный кэш (критически важно)
Хранить для каждого фото:
- `localIdentifier`
- `pHash` (UInt64)
- `featureVector` ([Float], опционально)
- дату последнего изменения

При следующих сканированиях:
- не пересчитывать хеши, если asset не менялся  
- считать только новые/изменённые фото

---

## 4. Оптимизировать поиск дубликатов
- Основная группировка по pHash  
- Для “почти похожих” использовать Hamming distance ≤ 8  
- Vision — только для кандидатов, а не для всех

---

## 5. Оптимизировать поиск похожих фото
- Сортировать фото по дате создания  
- Сравнивать только соседние элементы (окно ±5–10 фото), а не все со всеми  
- Использовать cosine similarity для feature vectors  
- Фильтровать по порогу (например, расстояние < 0.15)

---

## 6. Ввести пакетную обработку Vision
- Обрабатывать 20–50 фото за один batch  
- Выполнять в фоновом потоке (`Task(priority: .utility)`)  
- Убрать вызовы Vision на каждый отдельный asset

---

## 7. Улучшить отзывчивость UI
- После быстрой стадии сразу выводить первичные данные  
- Обновлять UI постепенно, по мере уточнения результатов  
- Никогда не блокировать `main thread`

---

## 8. Разделить тяжёлый процесс на чёткие стадии
1. Сбор метаданных  
2. Генерация pHash для всех фото  
3. Первичная группировка кандидатов  
4. Vision-уточнение только для нужных фото  
5. Финальная сборка групп (дубликаты / похожие)

---

## 9. Добавить отмену и перезапуск
- Если пользователь нажимает «Обновить», отменять текущие задачи  
- Пересчитывать только то, что реально нужно  
- Не очищать кэш полностью

---

## 10. Сохранить current API, переписать внутреннюю логику
- Методы `scanDuplicatesIfNeeded()` и `scanSimilarIfNeeded()` оставить  
- Переписать их реализацию на новый pipeline  
- Сохранить совместимость с текущими UI-группами

---

## 11. Общие требования к производительности
- Не использовать RAW/HEIC оригиналы  
- Работать только с миниатюрами  
- Исключить O(n²) сравнение  
- Видимое время сканирования: 1–2 секунды (Stage 1)

---

## 12. Дополнительно (желательно)
- Предзагрузка хешей в фоне  
- SQLite или файловое хранилище для feature vectors  
- Фоновая индексация медиатеки при запуске

